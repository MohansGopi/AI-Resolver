# ğŸ¤– AI-Resolver

**AI-Resolver** is a hybrid system that intelligently classifies and resolves technical issues using both traditional machine learning (offline mode) and fine-tuned large language models (online/server mode). It supports Windows and Linux troubleshooting using automated scripts.

---

## ğŸ“ Project Structure

```
AI-Resolver/
â”œâ”€â”€ App_/                  # Offline mode using SVM & TF-IDF
â”‚   â”œâ”€â”€ app_.py            # CLI app to take queries and classify
â”‚   â”œâ”€â”€ OflineController.py
â”‚   â”œâ”€â”€ Model/             # Pre-trained ML models
â”‚   â””â”€â”€ powerSHellScripts/ # Bash and PowerShell scripts for fixes
â”œâ”€â”€ Server/                # Online/server mode using LLM
â”‚   â”œâ”€â”€ sever.py           # Server entry point
â”‚   â”œâ”€â”€ controller.py
â”‚   â”œâ”€â”€ Finetune(5)/       # LoRA fine-tuned adapter and tokenizer
â”‚   â””â”€â”€ requirments.txt    # Server dependencies
```

---

## ğŸ§  Features

- âœ… Query classification via SVM & TF-IDF (Offline)
- âœ… PowerShell/Bash scripts to auto-resolve issues
- âœ… Server mode using LLM fine-tuned with LoRA
- âœ… Supports Windows & Linux environments
- âœ… Easy to extend with more issue types

---

## ğŸš€ Getting Started

### 1. Install Requirements

For offline app:

```bash
pip install -r App_/guide.txt
```

For server:

```bash
pip install -r Server/requirments.txt
```

### 2. Run Offline App

```bash
python App_/app_.py
```

### 3. Run Server Mode (Online)

```bash
python Server/sever.py
```

---

## ğŸ§ª Example Use Case

1. User enters query:  
   _"Outlook is not syncing on Windows 11"_

2. Offline:
   - Classifier maps to `Outlook app issue for window.ps1`
   - Runs the script directly

3. Server:
   - Sends query to fine-tuned LLM
   - Suggests appropriate fix or explanation

---

## ğŸ” PowerShell/Bash Scripts

These scripts are used to automatically resolve issues:

- **Outlook app/web issues**
- **Office app/web issues**
- **Network connectivity fixes**

Separate versions are provided for **Windows (.ps1)** and **Linux (.sh)**.

---

## ğŸ§© Fine-Tuning Details

LoRA-based fine-tuning is located under:

```
Server/Finetune(5)/content/output/
```

Includes tokenizer files and adapter weights for efficient LLM inference.

---

## ğŸ“„ License

This project is licensed for educational and research purposes. Contact the author for commercial use.

---

## âœï¸ Author

Built by Mohan â€“ for intelligent, scriptable IT issue resolution.
